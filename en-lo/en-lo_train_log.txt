onmt_build_vocab -config en_lo_config.yaml -n_sample -1
Corpus corpus_1's weight should be given. We default it to 1 for you.
[2022-04-09 14:14:02,896 INFO] Counter vocab from -1 samples.
[2022-04-09 14:14:02,896 INFO] n_sample=-1: Build vocab on full datasets.
[2022-04-09 14:14:02,901 INFO] corpus_1's transforms: TransformPipe()
[2022-04-09 14:14:04,717 INFO] Counters src:3811
[2022-04-09 14:14:04,717 INFO] Counters tgt:3979

onmt_train -config en_lo_config.yaml 
[2022-04-09 14:22:42,144 INFO] Missing transforms field for corpus_1 data, set to default: [].
[2022-04-09 14:22:42,144 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.
[2022-04-09 14:22:42,144 INFO] Missing transforms field for valid data, set to default: [].
[2022-04-09 14:22:42,144 INFO] Parsed 2 corpora from -data.
[2022-04-09 14:22:42,144 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-04-09 14:22:42,144 INFO] Loading vocab from text file...
[2022-04-09 14:22:42,144 INFO] Loading src vocabulary from run2/vocab.src
[2022-04-09 14:22:42,150 INFO] Loaded src vocab has 3811 tokens.
[2022-04-09 14:22:42,151 INFO] Loading tgt vocabulary from run2/vocab.tgt
[2022-04-09 14:22:42,156 INFO] Loaded tgt vocab has 3979 tokens.
[2022-04-09 14:22:42,157 INFO] Building fields with vocab in counters...
[2022-04-09 14:22:42,160 INFO]  * tgt vocab size: 3983.
[2022-04-09 14:22:42,164 INFO]  * src vocab size: 3813.
[2022-04-09 14:22:42,164 INFO]  * src vocab size = 3813
[2022-04-09 14:22:42,164 INFO]  * tgt vocab size = 3983
[2022-04-09 14:22:42,165 INFO] Building model...
[2022-04-09 14:22:46,177 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(3813, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(3983, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=3983, bias=True)
    (1): Cast()
    (2): LogSoftmax(dim=-1)
  )
)
[2022-04-09 14:22:46,179 INFO] encoder: 20867584
[2022-04-09 14:22:46,179 INFO] decoder: 29307791
[2022-04-09 14:22:46,179 INFO] * number of parameters: 50175375
[2022-04-09 14:22:46,180 INFO] Starting training on GPU: [0]
[2022-04-09 14:22:46,180 INFO] Start training loop and validate every 5000 steps...
[2022-04-09 14:22:46,181 INFO] corpus_1's transforms: TransformPipe()
[2022-04-09 14:22:46,181 INFO] Weighted corpora loaded so far:
                        * corpus_1: 1
[2022-04-09 14:24:18,230 INFO] Step 1000/100000; acc:  12.05; ppl: 236.21; xent: 5.46; lr: 0.00035; 17571/22166 tok/s;     92 sec
[2022-04-09 14:25:15,800 INFO] Weighted corpora loaded so far:
                        * corpus_1: 2
[2022-04-09 14:25:50,126 INFO] Step 2000/100000; acc:  35.60; ppl: 22.08; xent: 3.09; lr: 0.00070; 17710/22357 tok/s;    184 sec
[2022-04-09 14:27:27,337 INFO] Step 3000/100000; acc:  49.59; ppl:  9.52; xent: 2.25; lr: 0.00105; 16602/20985 tok/s;    281 sec
[2022-04-09 14:27:51,562 INFO] Weighted corpora loaded so far:
                        * corpus_1: 3
[2022-04-09 14:29:04,228 INFO] Step 4000/100000; acc:  55.51; ppl:  6.91; xent: 1.93; lr: 0.00140; 16756/21100 tok/s;    378 sec
[2022-04-09 14:30:46,642 INFO] Weighted corpora loaded so far:
                        * corpus_1: 4
[2022-04-09 14:30:55,537 INFO] Step 5000/100000; acc:  59.89; ppl:  5.52; xent: 1.71; lr: 0.00125; 14584/18442 tok/s;    489 sec
[2022-04-09 14:30:55,539 INFO] valid's transforms: TransformPipe()
[2022-04-09 14:31:01,678 INFO] Validation perplexity: 6.04916
[2022-04-09 14:31:01,678 INFO] Validation accuracy: 62.823
[2022-04-09 14:31:01,707 INFO] Saving checkpoint run2/en_lo_model_step_5000.pt
[2022-04-09 14:32:55,847 INFO] Step 6000/100000; acc:  63.56; ppl:  4.61; xent: 1.53; lr: 0.00114; 13478/17003 tok/s;    610 sec
[2022-04-09 14:33:57,792 INFO] Weighted corpora loaded so far:
                        * corpus_1: 5
[2022-04-09 14:34:47,840 INFO] Step 7000/100000; acc:  66.66; ppl:  3.98; xent: 1.38; lr: 0.00106; 14519/18306 tok/s;    722 sec
[2022-04-09 14:36:36,657 INFO] Step 8000/100000; acc:  68.91; ppl:  3.59; xent: 1.28; lr: 0.00099; 14815/18737 tok/s;    830 sec
[2022-04-09 14:36:56,227 INFO] Weighted corpora loaded so far:
                        * corpus_1: 6
[2022-04-09 14:38:26,527 INFO] Step 9000/100000; acc:  71.02; ppl:  3.26; xent: 1.18; lr: 0.00093; 14749/18588 tok/s;    940 sec
[2022-04-09 14:39:58,351 INFO] Weighted corpora loaded so far:
                        * corpus_1: 7
[2022-04-09 14:40:16,283 INFO] Step 10000/100000; acc:  72.94; ppl:  3.00; xent: 1.10; lr: 0.00088; 14830/18736 tok/s;   1050 sec
[2022-04-09 14:40:22,320 INFO] Validation perplexity: 4.02981
[2022-04-09 14:40:22,320 INFO] Validation accuracy: 70.7887
[2022-04-09 14:40:22,348 INFO] Saving checkpoint run2/en_lo_model_step_10000.pt
[2022-04-09 14:42:01,934 INFO] Step 11000/100000; acc:  73.97; ppl:  2.86; xent: 1.05; lr: 0.00084; 15332/19360 tok/s;   1156 sec
[2022-04-09 14:42:45,888 INFO] Weighted corpora loaded so far:
                        * corpus_1: 8
[2022-04-09 14:43:36,080 INFO] Step 12000/100000; acc:  75.47; ppl:  2.68; xent: 0.99; lr: 0.00081; 17254/21754 tok/s;   1250 sec
[2022-04-09 14:45:13,256 INFO] Step 13000/100000; acc:  76.39; ppl:  2.58; xent: 0.95; lr: 0.00078; 16669/21070 tok/s;   1347 sec
[2022-04-09 14:45:22,267 INFO] Weighted corpora loaded so far:
                        * corpus_1: 9
[2022-04-09 14:46:50,477 INFO] Step 14000/100000; acc:  77.45; ppl:  2.46; xent: 0.90; lr: 0.00075; 16628/20966 tok/s;   1444 sec
[2022-04-09 14:48:03,099 INFO] Weighted corpora loaded so far:
                        * corpus_1: 10
[2022-04-09 14:48:27,063 INFO] Step 15000/100000; acc:  78.50; ppl:  2.36; xent: 0.86; lr: 0.00072; 16859/21280 tok/s;   1541 sec
[2022-04-09 14:48:32,703 INFO] Validation perplexity: 3.76689
[2022-04-09 14:48:32,703 INFO] Validation accuracy: 72.494
[2022-04-09 14:48:32,718 INFO] Saving checkpoint run2/en_lo_model_step_15000.pt
[2022-04-09 14:50:09,460 INFO] Step 16000/100000; acc:  79.22; ppl:  2.29; xent: 0.83; lr: 0.00070; 15797/19966 tok/s;   1643 sec
[2022-04-09 14:50:46,952 INFO] Weighted corpora loaded so far:
                        * corpus_1: 11
[2022-04-09 14:51:45,340 INFO] Step 17000/100000; acc:  80.15; ppl:  2.21; xent: 0.79; lr: 0.00068; 16901/21297 tok/s;   1739 sec
[2022-04-09 14:53:22,866 INFO] Step 18000/100000; acc:  80.86; ppl:  2.15; xent: 0.76; lr: 0.00066; 16636/21026 tok/s;   1837 sec
[2022-04-09 14:53:24,300 INFO] Weighted corpora loaded so far:
                        * corpus_1: 12
[2022-04-09 14:55:01,059 INFO] Step 19000/100000; acc:  81.55; ppl:  2.09; xent: 0.74; lr: 0.00064; 16465/20758 tok/s;   1935 sec
[2022-04-09 14:56:08,152 INFO] Weighted corpora loaded so far:
                        * corpus_1: 13
[2022-04-09 14:56:38,911 INFO] Step 20000/100000; acc:  82.38; ppl:  2.03; xent: 0.71; lr: 0.00062; 16633/20992 tok/s;   2033 sec
[2022-04-09 14:56:44,450 INFO] Validation perplexity: 3.71153
[2022-04-09 14:56:44,450 INFO] Validation accuracy: 73.477
[2022-04-09 14:56:44,464 INFO] Saving checkpoint run2/en_lo_model_step_20000.pt
[2022-04-09 14:58:19,692 INFO] Step 21000/100000; acc:  82.82; ppl:  1.99; xent: 0.69; lr: 0.00061; 16084/20339 tok/s;   2134 sec
[2022-04-09 14:58:48,983 INFO] Weighted corpora loaded so far:
                        * corpus_1: 14
[2022-04-09 14:59:55,689 INFO] Step 22000/100000; acc:  83.37; ppl:  1.95; xent: 0.67; lr: 0.00060; 16846/21220 tok/s;   2230 sec
[2022-04-09 15:01:24,487 INFO] Weighted corpora loaded so far:
                        * corpus_1: 15
[2022-04-09 15:01:30,506 INFO] Step 23000/100000; acc:  84.03; ppl:  1.91; xent: 0.65; lr: 0.00058; 17139/21653 tok/s;   2324 sec
[2022-04-09 15:03:04,798 INFO] Step 24000/100000; acc:  84.47; ppl:  1.88; xent: 0.63; lr: 0.00057; 17127/21607 tok/s;   2419 sec
[2022-04-09 15:04:01,752 INFO] Weighted corpora loaded so far:
                        * corpus_1: 16
[2022-04-09 15:04:39,482 INFO] Step 25000/100000; acc:  85.04; ppl:  1.84; xent: 0.61; lr: 0.00056; 17160/21660 tok/s;   2513 sec
[2022-04-09 15:04:45,141 INFO] Validation perplexity: 3.7023
[2022-04-09 15:04:45,141 INFO] Validation accuracy: 74.0155
[2022-04-09 15:04:45,155 INFO] Saving checkpoint run2/en_lo_model_step_25000.pt
[2022-04-09 15:06:21,338 INFO] Step 26000/100000; acc:  85.43; ppl:  1.81; xent: 0.59; lr: 0.00055; 15881/20078 tok/s;   2615 sec
[2022-04-09 15:06:43,090 INFO] Weighted corpora loaded so far:
                        * corpus_1: 17
[2022-04-09 15:07:55,693 INFO] Step 27000/100000; acc:  85.90; ppl:  1.78; xent: 0.58; lr: 0.00054; 17166/21631 tok/s;   2710 sec
[2022-04-09 15:09:19,146 INFO] Weighted corpora loaded so far:
                        * corpus_1: 18
[2022-04-09 15:09:33,239 INFO] Step 28000/100000; acc:  86.38; ppl:  1.75; xent: 0.56; lr: 0.00053; 16659/21040 tok/s;   2807 sec
[2022-04-09 15:11:09,132 INFO] Step 29000/100000; acc:  86.64; ppl:  1.74; xent: 0.55; lr: 0.00052; 16778/21174 tok/s;   2903 sec
[2022-04-09 15:12:00,531 INFO] Weighted corpora loaded so far:
                        * corpus_1: 19
[2022-04-09 15:12:46,409 INFO] Step 30000/100000; acc:  87.13; ppl:  1.71; xent: 0.54; lr: 0.00051; 16637/20990 tok/s;   3000 sec
[2022-04-09 15:12:51,913 INFO] Validation perplexity: 3.74475
[2022-04-09 15:12:51,913 INFO] Validation accuracy: 74.427
[2022-04-09 15:12:51,927 INFO] Saving checkpoint run2/en_lo_model_step_30000.pt
[2022-04-09 15:14:44,534 INFO] Step 31000/100000; acc:  87.58; ppl:  1.68; xent: 0.52; lr: 0.00050; 13736/17369 tok/s;   3118 sec
[2022-04-09 15:15:02,342 INFO] Weighted corpora loaded so far:
                        * corpus_1: 20
[2022-04-09 15:16:37,362 INFO] Step 32000/100000; acc:  87.87; ppl:  1.67; xent: 0.51; lr: 0.00049; 14380/18115 tok/s;   3231 sec
[2022-04-09 15:18:07,004 INFO] Weighted corpora loaded so far:
                        * corpus_1: 21
[2022-04-09 15:18:33,036 INFO] Step 33000/100000; acc:  88.28; ppl:  1.65; xent: 0.50; lr: 0.00049; 14037/17733 tok/s;   3347 sec
[2022-04-09 15:20:27,529 INFO] Step 34000/100000; acc:  88.41; ppl:  1.64; xent: 0.49; lr: 0.00048; 14075/17781 tok/s;   3461 sec
[2022-04-09 15:21:19,663 INFO] Weighted corpora loaded so far:
                        * corpus_1: 22
[2022-04-09 15:22:22,687 INFO] Step 35000/100000; acc:  88.88; ppl:  1.61; xent: 0.48; lr: 0.00047; 14087/17760 tok/s;   3577 sec
[2022-04-09 15:22:28,869 INFO] Validation perplexity: 3.78846
[2022-04-09 15:22:28,869 INFO] Validation accuracy: 74.6006
[2022-04-09 15:22:28,887 INFO] Saving checkpoint run2/en_lo_model_step_35000.pt
[2022-04-09 15:24:27,363 INFO] Step 36000/100000; acc:  89.11; ppl:  1.60; xent: 0.47; lr: 0.00047; 13010/16443 tok/s;   3701 sec
[2022-04-09 15:24:36,674 INFO] Weighted corpora loaded so far:
                        * corpus_1: 23
[2022-04-09 15:26:23,125 INFO] Step 37000/100000; acc:  89.36; ppl:  1.59; xent: 0.46; lr: 0.00046; 13974/17609 tok/s;   3817 sec
[2022-04-09 15:27:43,324 INFO] Weighted corpora loaded so far:
                        * corpus_1: 24
[2022-04-09 15:28:15,459 INFO] Step 38000/100000; acc:  89.78; ppl:  1.57; xent: 0.45; lr: 0.00045; 14498/18317 tok/s;   3929 sec
[2022-04-09 15:30:04,300 INFO] Step 39000/100000; acc:  89.85; ppl:  1.56; xent: 0.45; lr: 0.00045; 14792/18691 tok/s;   4038 sec
[2022-04-09 15:30:45,557 INFO] Weighted corpora loaded so far:
                        * corpus_1: 25
[2022-04-09 15:31:53,457 INFO] Step 40000/100000; acc:  90.18; ppl:  1.55; xent: 0.44; lr: 0.00044; 14859/18725 tok/s;   4147 sec
[2022-04-09 15:31:59,496 INFO] Validation perplexity: 3.82049
[2022-04-09 15:31:59,497 INFO] Validation accuracy: 74.8267
[2022-04-09 15:31:59,517 INFO] Saving checkpoint run2/en_lo_model_step_40000.pt
[2022-04-09 15:33:49,610 INFO] Step 41000/100000; acc:  90.38; ppl:  1.54; xent: 0.43; lr: 0.00044; 13967/17645 tok/s;   4263 sec
[2022-04-09 15:33:50,078 INFO] Weighted corpora loaded so far:
                        * corpus_1: 26
[2022-04-09 15:35:43,991 INFO] Step 42000/100000; acc:  90.63; ppl:  1.53; xent: 0.42; lr: 0.00043; 14162/17860 tok/s;   4378 sec
[2022-04-09 15:36:57,772 INFO] Weighted corpora loaded so far:
                        * corpus_1: 27
[2022-04-09 15:37:41,166 INFO] Step 43000/100000; acc:  90.89; ppl:  1.51; xent: 0.41; lr: 0.00043; 13859/17500 tok/s;   4495 sec
[2022-04-09 15:39:32,966 INFO] Step 44000/100000; acc:  91.05; ppl:  1.50; xent: 0.41; lr: 0.00042; 14395/18203 tok/s;   4607 sec
[2022-04-09 15:40:05,626 INFO] Weighted corpora loaded so far:
                        * corpus_1: 28
[2022-04-09 15:41:21,606 INFO] Step 45000/100000; acc:  91.22; ppl:  1.50; xent: 0.40; lr: 0.00042; 14921/18789 tok/s;   4715 sec
[2022-04-09 15:41:27,659 INFO] Validation perplexity: 3.84755
[2022-04-09 15:41:27,659 INFO] Validation accuracy: 74.9102
[2022-04-09 15:41:27,688 INFO] Saving checkpoint run2/en_lo_model_step_45000.pt
[2022-04-09 15:43:09,637 INFO] Weighted corpora loaded so far:
                        * corpus_1: 29
[2022-04-09 15:43:17,606 INFO] Step 46000/100000; acc:  91.48; ppl:  1.48; xent: 0.39; lr: 0.00041; 14019/17713 tok/s;   4831 sec
[2022-04-09 15:45:06,520 INFO] Step 47000/100000; acc:  91.66; ppl:  1.48; xent: 0.39; lr: 0.00041; 14895/18793 tok/s;   4940 sec
[2022-04-09 15:46:06,611 INFO] Weighted corpora loaded so far:
                        * corpus_1: 30
[2022-04-09 15:46:55,408 INFO] Step 48000/100000; acc:  91.86; ppl:  1.47; xent: 0.38; lr: 0.00040; 14900/18804 tok/s;   5049 sec
[2022-04-09 15:48:46,594 INFO] Step 49000/100000; acc:  91.98; ppl:  1.46; xent: 0.38; lr: 0.00040; 14548/18386 tok/s;   5160 sec
[2022-04-09 15:49:10,978 INFO] Weighted corpora loaded so far:
                        * corpus_1: 31
[2022-04-09 15:50:38,804 INFO] Step 50000/100000; acc:  92.12; ppl:  1.45; xent: 0.37; lr: 0.00040; 14455/18219 tok/s;   5273 sec
[2022-04-09 15:50:44,986 INFO] Validation perplexity: 3.87342
[2022-04-09 15:50:44,986 INFO] Validation accuracy: 75.0156
[2022-04-09 15:50:45,016 INFO] Saving checkpoint run2/en_lo_model_step_50000.pt
[2022-04-09 15:52:20,776 INFO] Weighted corpora loaded so far:
                        * corpus_1: 32
[2022-04-09 15:52:38,007 INFO] Step 51000/100000; acc:  92.37; ppl:  1.44; xent: 0.37; lr: 0.00039; 13632/17219 tok/s;   5392 sec
[2022-04-09 15:54:28,549 INFO] Step 52000/100000; acc:  92.48; ppl:  1.44; xent: 0.36; lr: 0.00039; 14645/18498 tok/s;   5502 sec
[2022-04-09 15:55:13,080 INFO] Weighted corpora loaded so far:
                        * corpus_1: 33
[2022-04-09 15:56:04,094 INFO] Step 53000/100000; acc:  92.61; ppl:  1.43; xent: 0.36; lr: 0.00038; 16982/21408 tok/s;   5598 sec
[2022-04-09 15:57:40,858 INFO] Step 54000/100000; acc:  92.73; ppl:  1.43; xent: 0.36; lr: 0.00038; 16748/21173 tok/s;   5695 sec
[2022-04-09 15:57:54,147 INFO] Weighted corpora loaded so far:
                        * corpus_1: 34
[2022-04-09 15:59:17,158 INFO] Step 55000/100000; acc:  92.92; ppl:  1.42; xent: 0.35; lr: 0.00038; 16786/21159 tok/s;   5791 sec
[2022-04-09 15:59:22,939 INFO] Validation perplexity: 3.90389
[2022-04-09 15:59:22,940 INFO] Validation accuracy: 75.2116
[2022-04-09 15:59:22,954 INFO] Saving checkpoint run2/en_lo_model_step_55000.pt
[2022-04-09 16:00:37,397 INFO] Weighted corpora loaded so far:
                        * corpus_1: 35
[2022-04-09 16:01:00,195 INFO] Step 56000/100000; acc:  93.08; ppl:  1.41; xent: 0.34; lr: 0.00037; 15767/19915 tok/s;   5894 sec
[2022-04-09 16:02:44,382 INFO] Step 57000/100000; acc:  93.14; ppl:  1.41; xent: 0.34; lr: 0.00037; 15520/19606 tok/s;   5998 sec
[2022-04-09 16:03:27,626 INFO] Weighted corpora loaded so far:
                        * corpus_1: 36
[2022-04-09 16:04:32,507 INFO] Step 58000/100000; acc:  93.29; ppl:  1.40; xent: 0.34; lr: 0.00037; 15013/18910 tok/s;   6106 sec
[2022-04-09 16:06:21,472 INFO] Step 59000/100000; acc:  93.43; ppl:  1.40; xent: 0.33; lr: 0.00036; 14882/18818 tok/s;   6215 sec
[2022-04-09 16:06:28,014 INFO] Weighted corpora loaded so far:
                        * corpus_1: 37
[2022-04-09 16:08:12,523 INFO] Step 60000/100000; acc:  93.52; ppl:  1.39; xent: 0.33; lr: 0.00036; 14579/18384 tok/s;   6326 sec
[2022-04-09 16:08:18,442 INFO] Validation perplexity: 3.93234
[2022-04-09 16:08:18,443 INFO] Validation accuracy: 75.1781
[2022-04-09 16:08:18,470 INFO] Saving checkpoint run2/en_lo_model_step_60000.pt
[2022-04-09 16:09:34,351 INFO] Weighted corpora loaded so far:
                        * corpus_1: 38
[2022-04-09 16:10:09,001 INFO] Step 61000/100000; acc:  93.66; ppl:  1.39; xent: 0.33; lr: 0.00036; 13979/17639 tok/s;   6443 sec
[2022-04-09 16:11:59,039 INFO] Step 62000/100000; acc:  93.72; ppl:  1.38; xent: 0.32; lr: 0.00035; 14655/18529 tok/s;   6553 sec
[2022-04-09 16:12:34,610 INFO] Weighted corpora loaded so far:
                        * corpus_1: 39
[2022-04-09 16:13:50,823 INFO] Step 63000/100000; acc:  93.88; ppl:  1.38; xent: 0.32; lr: 0.00035; 14531/18309 tok/s;   6665 sec
[2022-04-09 16:15:41,065 INFO] Weighted corpora loaded so far:
                        * corpus_1: 40
[2022-04-09 16:15:43,013 INFO] Step 64000/100000; acc:  93.94; ppl:  1.37; xent: 0.32; lr: 0.00035; 14422/18229 tok/s;   6777 sec
[2022-04-09 16:17:31,277 INFO] Step 65000/100000; acc:  94.05; ppl:  1.37; xent: 0.31; lr: 0.00035; 14946/18850 tok/s;   6885 sec
[2022-04-09 16:17:37,083 INFO] Validation perplexity: 3.9228
[2022-04-09 16:17:37,084 INFO] Validation accuracy: 75.3764
[2022-04-09 16:17:37,108 INFO] Saving checkpoint run2/en_lo_model_step_65000.pt
[2022-04-09 16:18:44,892 INFO] Weighted corpora loaded so far:
                        * corpus_1: 41
[2022-04-09 16:19:26,814 INFO] Step 66000/100000; acc:  94.14; ppl:  1.36; xent: 0.31; lr: 0.00034; 14030/17700 tok/s;   7001 sec
[2022-04-09 16:21:18,777 INFO] Step 67000/100000; acc:  94.21; ppl:  1.36; xent: 0.31; lr: 0.00034; 14450/18274 tok/s;   7113 sec
[2022-04-09 16:21:46,267 INFO] Weighted corpora loaded so far:
                        * corpus_1: 42
[2022-04-09 16:23:12,222 INFO] Step 68000/100000; acc:  94.35; ppl:  1.36; xent: 0.30; lr: 0.00034; 14298/18012 tok/s;   7226 sec
[2022-04-09 16:24:54,373 INFO] Weighted corpora loaded so far:
                        * corpus_1: 43
[2022-04-09 16:25:04,558 INFO] Step 69000/100000; acc:  94.41; ppl:  1.35; xent: 0.30; lr: 0.00034; 14454/18264 tok/s;   7338 sec
[2022-04-09 16:26:58,235 INFO] Step 70000/100000; acc:  94.49; ppl:  1.35; xent: 0.30; lr: 0.00033; 14257/17982 tok/s;   7452 sec
[2022-04-09 16:27:04,268 INFO] Validation perplexity: 3.94156
[2022-04-09 16:27:04,270 INFO] Validation accuracy: 75.493
[2022-04-09 16:27:04,297 INFO] Saving checkpoint run2/en_lo_model_step_70000.pt
[2022-04-09 16:28:06,432 INFO] Weighted corpora loaded so far:
                        * corpus_1: 44
[2022-04-09 16:28:58,851 INFO] Step 71000/100000; acc:  94.59; ppl:  1.34; xent: 0.30; lr: 0.00033; 13419/16928 tok/s;   7573 sec
[2022-04-09 16:30:47,414 INFO] Step 72000/100000; acc:  94.65; ppl:  1.34; xent: 0.29; lr: 0.00033; 14879/18821 tok/s;   7681 sec
[2022-04-09 16:31:04,843 INFO] Weighted corpora loaded so far:
                        * corpus_1: 45
[2022-04-09 16:32:35,810 INFO] Step 73000/100000; acc:  94.77; ppl:  1.34; xent: 0.29; lr: 0.00033; 14949/18846 tok/s;   7790 sec
[2022-04-09 16:34:06,262 INFO] Weighted corpora loaded so far:
                        * corpus_1: 46
[2022-04-09 16:34:25,170 INFO] Step 74000/100000; acc:  94.80; ppl:  1.34; xent: 0.29; lr: 0.00032; 14878/18785 tok/s;   7899 sec
[2022-04-09 16:36:15,286 INFO] Step 75000/100000; acc:  94.90; ppl:  1.33; xent: 0.29; lr: 0.00032; 14721/18589 tok/s;   8009 sec
[2022-04-09 16:36:21,401 INFO] Validation perplexity: 3.96779
[2022-04-09 16:36:21,402 INFO] Validation accuracy: 75.5554
[2022-04-09 16:36:21,426 INFO] Saving checkpoint run2/en_lo_model_step_75000.pt
[2022-04-09 16:37:12,505 INFO] Weighted corpora loaded so far:
                        * corpus_1: 47
[2022-04-09 16:38:12,565 INFO] Step 76000/100000; acc:  94.97; ppl:  1.33; xent: 0.28; lr: 0.00032; 13785/17383 tok/s;   8126 sec
[2022-04-09 16:40:05,137 INFO] Step 77000/100000; acc:  94.98; ppl:  1.33; xent: 0.28; lr: 0.00032; 14330/18110 tok/s;   8239 sec
[2022-04-09 16:40:15,374 INFO] Weighted corpora loaded so far:
                        * corpus_1: 48
[2022-04-09 16:41:56,288 INFO] Step 78000/100000; acc:  95.09; ppl:  1.32; xent: 0.28; lr: 0.00032; 14563/18355 tok/s;   8350 sec
[2022-04-09 16:43:21,150 INFO] Weighted corpora loaded so far:
                        * corpus_1: 49
[2022-04-09 16:43:44,885 INFO] Step 79000/100000; acc:  95.19; ppl:  1.32; xent: 0.28; lr: 0.00031; 14967/18897 tok/s;   8459 sec
[2022-04-09 16:45:21,027 INFO] Step 80000/100000; acc:  95.19; ppl:  1.32; xent: 0.28; lr: 0.00031; 16787/21219 tok/s;   8555 sec
[2022-04-09 16:45:26,626 INFO] Validation perplexity: 3.98311
[2022-04-09 16:45:26,626 INFO] Validation accuracy: 75.5383
[2022-04-09 16:45:26,641 INFO] Saving checkpoint run2/en_lo_model_step_80000.pt
[2022-04-09 16:46:05,357 INFO] Weighted corpora loaded so far:
                        * corpus_1: 50
[2022-04-09 16:47:05,053 INFO] Step 81000/100000; acc:  95.28; ppl:  1.31; xent: 0.27; lr: 0.00031; 15579/19633 tok/s;   8659 sec
[2022-04-09 16:49:00,358 INFO] Step 82000/100000; acc:  95.35; ppl:  1.31; xent: 0.27; lr: 0.00031; 14047/17755 tok/s;   8774 sec
[2022-04-09 16:49:02,344 INFO] Weighted corpora loaded so far:
                        * corpus_1: 51
[2022-04-09 16:50:55,476 INFO] Step 83000/100000; acc:  95.40; ppl:  1.31; xent: 0.27; lr: 0.00031; 13997/17649 tok/s;   8889 sec
[2022-04-09 16:52:13,576 INFO] Weighted corpora loaded so far:
                        * corpus_1: 52
[2022-04-09 16:52:50,848 INFO] Step 84000/100000; acc:  95.49; ppl:  1.31; xent: 0.27; lr: 0.00030; 14135/17836 tok/s;   9005 sec
[2022-04-09 16:54:49,767 INFO] Step 85000/100000; acc:  95.52; ppl:  1.30; xent: 0.27; lr: 0.00030; 13603/17207 tok/s;   9124 sec
[2022-04-09 16:54:56,062 INFO] Validation perplexity: 3.99412
[2022-04-09 16:54:56,062 INFO] Validation accuracy: 75.6113
[2022-04-09 16:54:56,095 INFO] Saving checkpoint run2/en_lo_model_step_85000.pt
[2022-04-09 16:55:34,252 INFO] Weighted corpora loaded so far:
                        * corpus_1: 53
[2022-04-09 16:56:54,704 INFO] Step 86000/100000; acc:  95.57; ppl:  1.30; xent: 0.26; lr: 0.00030; 12963/16327 tok/s;   9249 sec
[2022-04-09 16:58:42,480 INFO] Weighted corpora loaded so far:
                        * corpus_1: 54
[2022-04-09 16:58:48,772 INFO] Step 87000/100000; acc:  95.62; ppl:  1.30; xent: 0.26; lr: 0.00030; 14150/17890 tok/s;   9363 sec
[2022-04-09 17:00:41,954 INFO] Step 88000/100000; acc:  95.66; ppl:  1.30; xent: 0.26; lr: 0.00030; 14278/18000 tok/s;   9476 sec
[2022-04-09 17:01:50,266 INFO] Weighted corpora loaded so far:
                        * corpus_1: 55
[2022-04-09 17:02:34,769 INFO] Step 89000/100000; acc:  95.72; ppl:  1.29; xent: 0.26; lr: 0.00030; 14414/18186 tok/s;   9589 sec
[2022-04-09 17:04:28,330 INFO] Step 90000/100000; acc:  95.77; ppl:  1.29; xent: 0.26; lr: 0.00029; 14242/18016 tok/s;   9702 sec
[2022-04-09 17:04:34,716 INFO] Validation perplexity: 4.0077
[2022-04-09 17:04:34,716 INFO] Validation accuracy: 75.7449
[2022-04-09 17:04:34,747 INFO] Saving checkpoint run2/en_lo_model_step_90000.pt
[2022-04-09 17:05:03,543 INFO] Weighted corpora loaded so far:
                        * corpus_1: 56
[2022-04-09 17:06:24,172 INFO] Step 91000/100000; acc:  95.80; ppl:  1.29; xent: 0.26; lr: 0.00029; 13929/17548 tok/s;   9818 sec
[2022-04-09 17:07:46,471 INFO] Weighted corpora loaded so far:
                        * corpus_1: 57
[2022-04-09 17:07:58,421 INFO] Step 92000/100000; acc:  95.85; ppl:  1.29; xent: 0.25; lr: 0.00029; 17159/21687 tok/s;   9912 sec
[2022-04-09 17:09:32,483 INFO] Step 93000/100000; acc:  95.91; ppl:  1.29; xent: 0.25; lr: 0.00029; 17184/21671 tok/s;  10006 sec
[2022-04-09 17:10:23,468 INFO] Weighted corpora loaded so far:
                        * corpus_1: 58
[2022-04-09 17:11:06,557 INFO] Step 94000/100000; acc:  95.97; ppl:  1.28; xent: 0.25; lr: 0.00029; 17232/21734 tok/s;  10100 sec
[2022-04-09 17:12:40,301 INFO] Step 95000/100000; acc:  96.02; ppl:  1.28; xent: 0.25; lr: 0.00029; 17280/21859 tok/s;  10194 sec
[2022-04-09 17:12:45,750 INFO] Validation perplexity: 4.02237
[2022-04-09 17:12:45,750 INFO] Validation accuracy: 75.7096
[2022-04-09 17:12:45,765 INFO] Saving checkpoint run2/en_lo_model_step_95000.pt
[2022-04-09 17:13:02,215 INFO] Weighted corpora loaded so far:
                        * corpus_1: 59
[2022-04-09 17:14:21,412 INFO] Step 96000/100000; acc:  96.01; ppl:  1.28; xent: 0.25; lr: 0.00029; 15996/20160 tok/s;  10295 sec
[2022-04-09 17:15:36,543 INFO] Weighted corpora loaded so far:
                        * corpus_1: 60
[2022-04-09 17:15:55,106 INFO] Step 97000/100000; acc:  96.10; ppl:  1.28; xent: 0.24; lr: 0.00028; 17285/21831 tok/s;  10389 sec
[2022-04-09 17:17:30,576 INFO] Step 98000/100000; acc:  96.11; ppl:  1.28; xent: 0.24; lr: 0.00028; 16942/21396 tok/s;  10484 sec
[2022-04-09 17:18:14,544 INFO] Weighted corpora loaded so far:
                        * corpus_1: 61
[2022-04-09 17:19:04,600 INFO] Step 99000/100000; acc:  96.16; ppl:  1.27; xent: 0.24; lr: 0.00028; 17214/21696 tok/s;  10578 sec
[2022-04-09 17:20:42,265 INFO] Step 100000/100000; acc:  96.21; ppl:  1.27; xent: 0.24; lr: 0.00028; 16575/20959 tok/s;  10676 sec
[2022-04-09 17:20:47,758 INFO] Validation perplexity: 4.02953
[2022-04-09 17:20:47,758 INFO] Validation accuracy: 75.8055
[2022-04-09 17:20:47,773 INFO] Saving checkpoint run2/en_lo_model_step_100000.pt